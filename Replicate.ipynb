{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "os.chdir(r'C:\\Users\\INHA\\iCloudDrive\\FinanceLab\\Paper\\replicate\\Gu_et_al_2020\\data')\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Firm Characteristics Data\n",
    "\n",
    "The newest version of firm characteristics data are downloaded from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 20s\n",
      "Wall time: 6min 27s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>DATE</th>\n",
       "      <th>mvel1</th>\n",
       "      <th>RET</th>\n",
       "      <th>prc</th>\n",
       "      <th>SHROUT</th>\n",
       "      <th>beta</th>\n",
       "      <th>betasq</th>\n",
       "      <th>chmom</th>\n",
       "      <th>dolvol</th>\n",
       "      <th>...</th>\n",
       "      <th>baspread</th>\n",
       "      <th>ill</th>\n",
       "      <th>maxret</th>\n",
       "      <th>retvol</th>\n",
       "      <th>std_dolvol</th>\n",
       "      <th>std_turn</th>\n",
       "      <th>zerotrade</th>\n",
       "      <th>sic2</th>\n",
       "      <th>bm</th>\n",
       "      <th>bm_ia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10006</td>\n",
       "      <td>1957-05-31</td>\n",
       "      <td>87191.00</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>61.000</td>\n",
       "      <td>1412</td>\n",
       "      <td>1.105519</td>\n",
       "      <td>1.222172</td>\n",
       "      <td>0.206966</td>\n",
       "      <td>9.224909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008677</td>\n",
       "      <td>1.582667e-07</td>\n",
       "      <td>0.020576</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>0.595904</td>\n",
       "      <td>0.403419</td>\n",
       "      <td>1.407496e-07</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10014</td>\n",
       "      <td>1957-05-31</td>\n",
       "      <td>4089.25</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>3.500</td>\n",
       "      <td>1487</td>\n",
       "      <td>0.353767</td>\n",
       "      <td>0.125151</td>\n",
       "      <td>-0.012857</td>\n",
       "      <td>6.335719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038108</td>\n",
       "      <td>2.006570e-05</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.040580</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>0.594928</td>\n",
       "      <td>1.548958e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10022</td>\n",
       "      <td>1957-05-31</td>\n",
       "      <td>10219.50</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>7.000</td>\n",
       "      <td>1514</td>\n",
       "      <td>0.955740</td>\n",
       "      <td>0.913438</td>\n",
       "      <td>0.127109</td>\n",
       "      <td>6.631508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015120</td>\n",
       "      <td>3.056159e-06</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.012231</td>\n",
       "      <td>0.997025</td>\n",
       "      <td>0.621414</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10030</td>\n",
       "      <td>1957-05-31</td>\n",
       "      <td>56729.00</td>\n",
       "      <td>0.029255</td>\n",
       "      <td>48.375</td>\n",
       "      <td>1207</td>\n",
       "      <td>0.875973</td>\n",
       "      <td>0.767328</td>\n",
       "      <td>0.187076</td>\n",
       "      <td>9.827079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010752</td>\n",
       "      <td>3.829632e-08</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>0.496714</td>\n",
       "      <td>1.062983</td>\n",
       "      <td>4.088753e-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10057</td>\n",
       "      <td>1957-05-31</td>\n",
       "      <td>37000.00</td>\n",
       "      <td>-0.027027</td>\n",
       "      <td>71.000</td>\n",
       "      <td>500</td>\n",
       "      <td>1.160347</td>\n",
       "      <td>1.346405</td>\n",
       "      <td>0.045401</td>\n",
       "      <td>7.415777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009028</td>\n",
       "      <td>7.115245e-07</td>\n",
       "      <td>0.017123</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.633949</td>\n",
       "      <td>0.302686</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   permno       DATE     mvel1       RET     prc  SHROUT      beta    betasq  \\\n",
       "0   10006 1957-05-31  87191.00  0.004049  61.000    1412  1.105519  1.222172   \n",
       "1   10014 1957-05-31   4089.25  0.272727   3.500    1487  0.353767  0.125151   \n",
       "2   10022 1957-05-31  10219.50  0.037037   7.000    1514  0.955740  0.913438   \n",
       "3   10030 1957-05-31  56729.00  0.029255  48.375    1207  0.875973  0.767328   \n",
       "4   10057 1957-05-31  37000.00 -0.027027  71.000     500  1.160347  1.346405   \n",
       "\n",
       "      chmom    dolvol  ...  baspread           ill    maxret    retvol  \\\n",
       "0  0.206966  9.224909  ...  0.008677  1.582667e-07  0.020576  0.008402   \n",
       "1 -0.012857  6.335719  ...  0.038108  2.006570e-05  0.050000  0.040580   \n",
       "2  0.127109  6.631508  ...  0.015120  3.056159e-06  0.019608  0.012231   \n",
       "3  0.187076  9.827079  ...  0.010752  3.829632e-08  0.016216  0.008002   \n",
       "4  0.045401  7.415777  ...  0.009028  7.115245e-07  0.017123  0.011561   \n",
       "\n",
       "   std_dolvol  std_turn     zerotrade  sic2  bm  bm_ia  \n",
       "0    0.595904  0.403419  1.407496e-07  37.0 NaN    NaN  \n",
       "1    0.800049  0.594928  1.548958e-07   NaN NaN    NaN  \n",
       "2    0.997025  0.621414  1.000000e+00   NaN NaN    NaN  \n",
       "3    0.496714  1.062983  4.088753e-08   NaN NaN    NaN  \n",
       "4    0.633949  0.302686  3.000000e+00   NaN NaN    NaN  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#start date and end date of the sample\n",
    "start_date, end_date = 19570531, 20161231\n",
    "\n",
    "#load firm characteristics data\n",
    "data_ch = pd.read_csv('GKX_20201231.csv')\n",
    "data_ch = data_ch[(data_ch['DATE']>=start_date)&(data_ch['DATE']<=end_date)].reset_index(drop=True)\n",
    "data_ch['DATE'] = pd.to_datetime(data_ch['DATE'], format='%Y%m%d')+pd.offsets.MonthEnd(0)\n",
    "characteristics = list(set(data_ch.columns).difference({'permno','DATE','SHROUT','mve0','sic2','RET','prc'}))\n",
    "\n",
    "data_ch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick out Top 1000 and Bottom 1000 Firms\n",
    "\n",
    "Next, let's pick out the top 1000 and bottom 1000 firms with respect to market capitalization to see the difference of predictability between big firms and small firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick top 1000 firms by market value each year\n",
    "data_ch_top = data_ch.sort_values('mvel1', ascending=False).groupby('DATE').head(1000).reset_index(drop=True)\n",
    "#Pcik bottom 1000 firms by market value each year\n",
    "data_ch_bot = data_ch.sort_values('mvel1', ascending=False).groupby('DATE').head(1000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Characteristics\n",
    "\n",
    "According to thwe paper, the missing data are replaced by the cross-sectional median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "permno            0\n",
       "DATE              0\n",
       "mvel1          3038\n",
       "RET               0\n",
       "prc           19070\n",
       "              ...  \n",
       "std_turn     305622\n",
       "zerotrade    309732\n",
       "sic2         257771\n",
       "bm           989890\n",
       "bm_ia        989890\n",
       "Length: 101, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing data before filling\n",
    "data_ch.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 6s\n",
      "Wall time: 3min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#fill nan with cross-sectional median\n",
    "for ch in characteristics:\n",
    "    data_ch[ch] = data_ch.groupby('DATE')[ch].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "permno            0\n",
       "DATE              0\n",
       "mvel1             0\n",
       "RET               0\n",
       "prc           19070\n",
       "              ...  \n",
       "std_turn          0\n",
       "zerotrade         0\n",
       "sic2         257771\n",
       "bm            67854\n",
       "bm_ia         67854\n",
       "Length: 101, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing data after filling\n",
    "data_ch.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are some characeristics that are all missing at some time point, we still encounter missing data after the filling process. Then, let's try to fill the remaining nan with time-series median. Unfortunately, after filling nan with time-series median, na still exists. \n",
    "Since there is no further instruction of how to deal with remaining nan in the data, after consulting some replication code online, I fill the remaining nan with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['prc', 'mve0', 'sic2'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for ch in characteristics:\n",
    "    data_ch[ch] = data_ch[ch].fillna(0)\n",
    "\n",
    "data_ch.columns[data_ch.isnull().sum()!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we do not have missing characteristics in dataset.\n",
    "\n",
    "Then, do the same process to top and bottom 1000 firms data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan(data_ch, characteristics):\n",
    "    for ch in characteristics:\n",
    "        data_ch[ch] = data_ch.groupby('DATE')[ch].transform(lambda x: x.fillna(x.median()))\n",
    "    for ch in characteristics:\n",
    "        data_ch[ch] = data_ch[ch].fillna(0)\n",
    "    return data_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ch_top = fill_nan(data_ch_top, characteristics)\n",
    "data_ch_bot = fill_nan(data_ch_bot, characteristics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform SIC Code into Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dummies for SIC code\n",
    "def get_sic_dummies(data_ch):\n",
    "    sic_dummies = pd.get_dummies(data_ch['sic2'].fillna(999).astype(int), prefix='sic').drop('sic_999', axis=1)\n",
    "    data_ch_d = pd.concat([data_ch, sic_dummies], axis=1)\n",
    "    data_ch_d.drop(['prc', 'SHROUT', 'mve0', 'sic2'], inplace=True, axis=1)\n",
    "    return data_ch_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ch_d = get_sic_dummies(data_ch)\n",
    "data_ch_top_d = get_sic_dummies(data_ch_top)\n",
    "data_ch_bot_d = get_sic_dummies(data_ch_bot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macroeconomic Predictors Data\n",
    "\n",
    "The eight macroeconomic predictors follows the definitions by Welch and Goyal (2008, RFS). The data are available on Prof Goyal's website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yyyymm</th>\n",
       "      <th>dp_sp</th>\n",
       "      <th>ep_sp</th>\n",
       "      <th>bm_sp</th>\n",
       "      <th>ntis</th>\n",
       "      <th>tbl</th>\n",
       "      <th>tms</th>\n",
       "      <th>dfy</th>\n",
       "      <th>svar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1957-05-31</td>\n",
       "      <td>0.036475</td>\n",
       "      <td>0.071965</td>\n",
       "      <td>0.564039</td>\n",
       "      <td>0.028849</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.000482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1957-06-30</td>\n",
       "      <td>0.036521</td>\n",
       "      <td>0.072198</td>\n",
       "      <td>0.565877</td>\n",
       "      <td>0.030528</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.000579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1957-07-31</td>\n",
       "      <td>0.036318</td>\n",
       "      <td>0.071732</td>\n",
       "      <td>0.560057</td>\n",
       "      <td>0.032346</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.000554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1957-08-31</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>0.076367</td>\n",
       "      <td>0.588005</td>\n",
       "      <td>0.035854</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.002147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1957-09-30</td>\n",
       "      <td>0.041490</td>\n",
       "      <td>0.081801</td>\n",
       "      <td>0.624151</td>\n",
       "      <td>0.034363</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.001517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      yyyymm     dp_sp     ep_sp     bm_sp      ntis     tbl     tms     dfy  \\\n",
       "0 1957-05-31  0.036475  0.071965  0.564039  0.028849  0.0306  0.0042  0.0078   \n",
       "1 1957-06-30  0.036521  0.072198  0.565877  0.030528  0.0329  0.0032  0.0072   \n",
       "2 1957-07-31  0.036318  0.071732  0.560057  0.032346  0.0316  0.0049  0.0074   \n",
       "3 1957-08-31  0.038700  0.076367  0.588005  0.035854  0.0337  0.0030  0.0072   \n",
       "4 1957-09-30  0.041490  0.081801  0.624151  0.034363  0.0353  0.0011  0.0081   \n",
       "\n",
       "       svar  \n",
       "0  0.000482  \n",
       "1  0.000579  \n",
       "2  0.000554  \n",
       "3  0.002147  \n",
       "4  0.001517  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loead macroeconomic predictors data\n",
    "data_ma = pd.read_csv('PredictorData2022.xlsx - Monthly.csv')\n",
    "data_ma = data_ma[(data_ma['yyyymm']>=start_date//100) & (data_ma['yyyymm']<=end_date//100)].reset_index(drop=True)\n",
    "\n",
    "# construct predictor\n",
    "ma_predictors = ['dp_sp', 'ep_sp', 'bm_sp', 'ntis', 'tbl', 'tms', 'dfy', 'svar']\n",
    "data_ma['Index'] = data_ma['Index'].str.replace(',', '').astype('float64')\n",
    "data_ma['dp_sp'] = data_ma['D12']/data_ma['Index']\n",
    "data_ma['ep_sp'] = data_ma['E12']/data_ma['Index']\n",
    "\n",
    "data_ma.rename({'b/m': 'bm_sp'}, axis=1, inplace=True)\n",
    "\n",
    "data_ma['tms'] = data_ma['lty']-data_ma['tbl']\n",
    "data_ma['dfy'] = data_ma['BAA']-data_ma['AAA']\n",
    "\n",
    "data_ma = data_ma[['yyyymm']+ma_predictors]\n",
    "data_ma['yyyymm'] = pd.to_datetime(data_ma['yyyymm'], format='%Y%m')+pd.offsets.MonthEnd(0)\n",
    "data_ma.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the Dataset including all the Features\n",
    "\n",
    "Besides adding the interaction terms, this function also transform the data into (-1,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def interactions(data_ch, data_ma, chracteristics, ma_predictors, minmax=True):\n",
    "    # construct interactions between firm characteristics and macroeconomic predictors\n",
    "    data = data_ch.copy()\n",
    "    data_ma_long = pd.merge(data[['DATE']], data_ma, left_on='DATE', right_on='yyyymm', how='left')\n",
    "    data = data.reset_index(drop=True)\n",
    "    data_ma_long = data_ma_long.reset_index(drop=True)\n",
    "    for fc in characteristics:\n",
    "        for mp in ma_predictors:\n",
    "            data[fc+'*'+mp] = data[fc]*data_ma_long[mp]\n",
    "            \n",
    "    features = list(set(data.columns).difference({'permo', 'DATE', 'RET'})) # a list storing all 920 features used\n",
    "    \n",
    "    if minmax:\n",
    "       X = MinMaxScaler((-1,1)).fit_transform(data[features])\n",
    "       X = pd.DataFrame(X, columns=features)\n",
    "    else:\n",
    "        X = data[features]\n",
    "    y = data['RET']\n",
    "    print(f\"The shape of the data is {data.shape}\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Sample into Training Set, Validation Set and Testing Set\n",
    "\n",
    "According to the paper, the authors use first 18 years (1957-1974) for training, last 30 years (19878-2016), for out-of-sample testing, and 12 years middle(1975-1986) for tuning hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_valid = np.datetime64('1975-01-31')\n",
    "start_date_test = np.datetime64('1987-01-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_test(data):\n",
    "    \n",
    "    #training set_start_date_valid = np.datetime64('1957-05-31')\n",
    "    X_train, y_train = interactions(data[data['DATE']<start_date_valid], data_ma[data_ma['yyyymm']<start_date_valid], characteristics, ma_predictors)\n",
    "    \n",
    "    #validation set\n",
    "    X_valid, y_valid = interactions(data[(data['DATE']<start_date_test)&(data['DATE']>=start_date_valid)], data_ma[(data_ma['yyyymm']>=start_date_valid)], characteristics, ma_predictors)\n",
    "    \n",
    "    #test set\n",
    "    X_test, y_test = interactions(data[data['DATE']>=start_date_test], data_ma[data_ma['yyyymm']>=start_date_test], characteristics,ma_predicors)\n",
    "    \n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.45 GiB for an array with shape (915, 212000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\INHA\\Desktop\\새 폴더\\Empirical_Asset_Pricing_via_Machine_Learning\\Replicate.ipynb Cell 25\u001b[0m in \u001b[0;36mtrain_valid_test\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/INHA/Desktop/%EC%83%88%20%ED%8F%B4%EB%8D%94/Empirical_Asset_Pricing_via_Machine_Learning/Replicate.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_valid_test\u001b[39m(data):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/INHA/Desktop/%EC%83%88%20%ED%8F%B4%EB%8D%94/Empirical_Asset_Pricing_via_Machine_Learning/Replicate.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/INHA/Desktop/%EC%83%88%20%ED%8F%B4%EB%8D%94/Empirical_Asset_Pricing_via_Machine_Learning/Replicate.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m#training set_start_date_valid = np.datetime64('1957-05-31')\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/INHA/Desktop/%EC%83%88%20%ED%8F%B4%EB%8D%94/Empirical_Asset_Pricing_via_Machine_Learning/Replicate.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     X_train, y_train \u001b[39m=\u001b[39m interactions(data[data[\u001b[39m'\u001b[39;49m\u001b[39mDATE\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m<\u001b[39;49mstart_date_valid], data_ma[data_ma[\u001b[39m'\u001b[39;49m\u001b[39myyyymm\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m<\u001b[39;49mstart_date_valid], characteristics, ma_predictors)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/INHA/Desktop/%EC%83%88%20%ED%8F%B4%EB%8D%94/Empirical_Asset_Pricing_via_Machine_Learning/Replicate.ipynb#X34sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m#validation set\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/INHA/Desktop/%EC%83%88%20%ED%8F%B4%EB%8D%94/Empirical_Asset_Pricing_via_Machine_Learning/Replicate.ipynb#X34sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     X_valid, y_valid \u001b[39m=\u001b[39m interactions(data[(data[\u001b[39m'\u001b[39m\u001b[39mDATE\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m<\u001b[39mstart_date_test)\u001b[39m&\u001b[39m(data[\u001b[39m'\u001b[39m\u001b[39mDATE\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m>\u001b[39m\u001b[39m=\u001b[39mstart_date_valid)], data_ma[(data_ma[\u001b[39m'\u001b[39m\u001b[39myyyymm\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m>\u001b[39m\u001b[39m=\u001b[39mstart_date_valid)], characteristics, ma_predictors)\n",
      "\u001b[1;32mc:\\Users\\INHA\\Desktop\\새 폴더\\Empirical_Asset_Pricing_via_Machine_Learning\\Replicate.ipynb Cell 25\u001b[0m in \u001b[0;36minteractions\u001b[1;34m(data_ch, data_ma, chracteristics, ma_predictors, minmax)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/INHA/Desktop/%EC%83%88%20%ED%8F%B4%EB%8D%94/Empirical_Asset_Pricing_via_Machine_Learning/Replicate.ipynb#X34sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(data\u001b[39m.\u001b[39mcolumns)\u001b[39m.\u001b[39mdifference({\u001b[39m'\u001b[39m\u001b[39mpermo\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDATE\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRET\u001b[39m\u001b[39m'\u001b[39m})) \u001b[39m# a list storing all 920 features used\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/INHA/Desktop/%EC%83%88%20%ED%8F%B4%EB%8D%94/Empirical_Asset_Pricing_via_Machine_Learning/Replicate.ipynb#X34sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mif\u001b[39;00m minmax:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/INHA/Desktop/%EC%83%88%20%ED%8F%B4%EB%8D%94/Empirical_Asset_Pricing_via_Machine_Learning/Replicate.ipynb#X34sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m    X \u001b[39m=\u001b[39m MinMaxScaler((\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m))\u001b[39m.\u001b[39;49mfit_transform(data[features])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/INHA/Desktop/%EC%83%88%20%ED%8F%B4%EB%8D%94/Empirical_Asset_Pricing_via_Machine_Learning/Replicate.ipynb#X34sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m    X \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(X, columns\u001b[39m=\u001b[39mfeatures)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/INHA/Desktop/%EC%83%88%20%ED%8F%B4%EB%8D%94/Empirical_Asset_Pricing_via_Machine_Learning/Replicate.ipynb#X34sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\INHA\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\base.py:867\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    864\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    866\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X)\n\u001b[0;32m    868\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\INHA\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:499\u001b[0m, in \u001b[0;36mMinMaxScaler.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[39m\"\"\"Scale features of X according to feature_range.\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \n\u001b[0;32m    487\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39m    Transformed data.\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    497\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 499\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    500\u001b[0m     X,\n\u001b[0;32m    501\u001b[0m     copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy,\n\u001b[0;32m    502\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    503\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    504\u001b[0m     reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    505\u001b[0m )\n\u001b[0;32m    507\u001b[0m X \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale_\n\u001b[0;32m    508\u001b[0m X \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_\n",
      "File \u001b[1;32mc:\\Users\\INHA\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\INHA\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\utils\\validation.py:924\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    917\u001b[0m     \u001b[39mif\u001b[39;00m n_features \u001b[39m<\u001b[39m ensure_min_features:\n\u001b[0;32m    918\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    919\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m feature(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    920\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m a minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    921\u001b[0m             \u001b[39m%\u001b[39m (n_features, array\u001b[39m.\u001b[39mshape, ensure_min_features, context)\n\u001b[0;32m    922\u001b[0m         )\n\u001b[1;32m--> 924\u001b[0m \u001b[39mif\u001b[39;00m copy \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39;49mmay_share_memory(array, array_orig):\n\u001b[0;32m    925\u001b[0m     array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(array, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39morder)\n\u001b[0;32m    927\u001b[0m \u001b[39mreturn\u001b[39;00m array\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mmay_share_memory\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\INHA\\anaconda3\\envs\\ML\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\INHA\\anaconda3\\envs\\ML\\lib\\site-packages\\pandas\\core\\frame.py:918\u001b[0m, in \u001b[0;36mDataFrame._values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    916\u001b[0m blocks \u001b[39m=\u001b[39m mgr\u001b[39m.\u001b[39mblocks\n\u001b[0;32m    917\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(blocks) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues\n\u001b[0;32m    920\u001b[0m arr \u001b[39m=\u001b[39m blocks[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m    921\u001b[0m \u001b[39mif\u001b[39;00m arr\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    922\u001b[0m     \u001b[39m# non-2D ExtensionArray\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\INHA\\anaconda3\\envs\\ML\\lib\\site-packages\\pandas\\core\\frame.py:10889\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  10816\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m  10817\u001b[0m \u001b[39mReturn a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[0;32m  10818\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10886\u001b[0m \u001b[39m       ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[0;32m  10887\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m  10888\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate_inplace()\n\u001b[1;32m> 10889\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array()\n",
      "File \u001b[1;32mc:\\Users\\INHA\\anaconda3\\envs\\ML\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1589\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1587\u001b[0m             arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1588\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1589\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interleave(dtype\u001b[39m=\u001b[39;49mdtype, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[0;32m   1590\u001b[0m     \u001b[39m# The underlying data was copied within _interleave\u001b[39;00m\n\u001b[0;32m   1591\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\INHA\\anaconda3\\envs\\ML\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1628\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1625\u001b[0m \u001b[39melif\u001b[39;00m is_dtype_equal(dtype, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1626\u001b[0m     dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1628\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mempty(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m   1630\u001b[0m itemmask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m   1632\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m na_value \u001b[39mis\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n\u001b[0;32m   1633\u001b[0m     \u001b[39m# much more performant than using to_numpy below\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.45 GiB for an array with shape (915, 212000) and data type float64"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = train_valid_test(data_ch_top_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonHome_p36",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
